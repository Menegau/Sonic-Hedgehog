{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detec√ß√£o de valores an√¥malos\n",
    "============================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adelie' 'Chinstrap' 'Gentoo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv\\ilumpy\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "df = sns.load_dataset('penguins')\n",
    "dfcopia = df.copy()\n",
    "dfcopia = dfcopia.dropna(axis=0)\n",
    "especies = dfcopia['species'].unique()\n",
    "print(especies)\n",
    "\n",
    "dfcopia['specie numerica'] = 0\n",
    "\n",
    "i = 0\n",
    "for pinguin in dfcopia['species']:\n",
    "    #print(pinguin)\n",
    "    if pinguin == 'Adelie':\n",
    "        dfcopia['specie numerica'].iloc[i] = 1\n",
    "        i += 1\n",
    "    elif pinguin == 'Chinstrap':\n",
    "        dfcopia['specie numerica'].iloc[i] = 2\n",
    "        i += 1\n",
    "    elif pinguin == 'Gentoo':\n",
    "        dfcopia['specie numerica'].iloc[i] = 3\n",
    "        i += 1\n",
    "    #print(dfcopia['species'].iloc[i-1],dfcopia['specie numerica'].iloc[i-1])\n",
    "\n",
    "features_numericos = [\"bill_length_mm\",\"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "df_numericos = dfcopia[features_numericos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(df_numericos)\n",
    "X_norm = sc.transform(df_numericos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]\n",
    "TARGET = [\"specie numerica\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler() #Definindo o normalizador\n",
    "X_norm = scaler.fit_transform(dfcopia[FEATURES].values) #Normalizando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizamos os dados a fim de realizarmos os PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.DataFrame(X_norm,columns = FEATURES) #Criando o DataFrame a partir com dados normalizados, que √© um array de numpy\n",
    "df_norm = pd.concat([df_norm,pd.Series(dfcopia['specie numerica']).reset_index(drop=True)],axis=1) #Concatenando a coluna 'price' ao DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "X = df_norm[FEATURES] #Definindo o X como as features\n",
    "y = df_norm['specie numerica']  #Definindo o y como o target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEMENTE_ALEATORIA = 6144\n",
    "N_EXEMPLOS = 300\n",
    "N_FEATURES = 3\n",
    "FRACAO_OUTLIERS = 0.10\n",
    "\n",
    "n_outliers = int(FRACAO_OUTLIERS * N_EXEMPLOS)\n",
    "n_inliers = N_EXEMPLOS - n_outliers\n",
    "\n",
    "rng = np.random.RandomState(SEMENTE_ALEATORIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>specie numerica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.269091</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bill_length_mm  bill_depth_mm  flipper_length_mm  specie numerica\n",
       "0        0.254545       0.666667           0.152542                1\n",
       "1        0.269091       0.511905           0.237288                1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= df_norm\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:, :-1]\n",
    "y=data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=10, contamination=0.1)\n",
    "\n",
    "y_pred = clf.fit_predict(X_pca)\n",
    "n_errors = (y_pred != y).sum()\n",
    "X_scores = clf.negative_outlier_factor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lofs_index = np.where(y_pred!=1)\n",
    "values = X_pca[lofs_index]\n",
    "plt.title(\"Local Outlier Factor (LOF)\")\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], label=\"Pinguins Normais\")\n",
    "plt.scatter(values[:,0],values[:,1], color='r', label=\"Pinguins coisados\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo Local Outlier Factor (LOF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Local Outlier Factor (LOF) √© um algoritmo de detec√ß√£o de outliers que utiliza a dist√¢ncia entre os pontos para realizar a sua detec√ß√£o.\n",
    "\n",
    "Este algoritmo usa o conceito dos $k$ vizinhos mais pr√≥ximos que vimos no algoritmo de aprendizado supervisionado $k$‚Äã-NN. Primeiramente definimos o conjunto $N_k(A)$ que cont√©m todos os $k$ vizinhos do exemplo $A$. Note que pelo motivo de poder haver empate entre as dist√¢ncias, o conjunto $N_k(A)$ pode ter mais que $k$ itens.\n",
    "\n",
    "Tendo o conjunto $N_k(A)$, definimos a dist√¢ncia $k\\textrm{-dist}(A)$ como sendo a dist√¢ncia entre o exemplo $A$ e seu vizinho $k$. Em outras palavras, a dist√¢ncia $k\\textrm{-dist}(A)$ √© a maior dist√¢ncia entre $A$ e os elementos do conjunto $N_k(A)$.\n",
    "\n",
    "Definimos em seguida a dist√¢ncia de alcan√ßabilidade (*reachability distance*) como sendo:\n",
    "\n",
    "$$\n",
    "\\textrm{reachability-dist}_k(A,B)=\\max \\{ k\\textrm{-dist}(B), \\textrm{dist}(A,B)\\}\n",
    "$$\n",
    "\n",
    "Na equa√ß√£o acima, $\\textrm{dist}(A,B)$ √© a dist√¢ncia entre $A$ e $B$.\n",
    "\n",
    "A dist√¢ncia de alcan√ßabilidade entre $A$ e $B$ ser√° ent√£o a pr√≥pria dist√¢ncia entre $A$ e $B$ <u>ou</u> no m√≠nimo a dist√¢ncia entre $B$ e seu $k$ vizinho. Esta dist√¢ncia representa &ldquo;o qu√£o dif√≠cil&rdquo; √© chegar em $A$ a partir de $B$. Quanto maior essa dist√¢ncia, mais distante $A$ est√° de $B$ neste contexto.\n",
    "\n",
    "Seguimos definindo a dist√¢ncia de alcan√ßabilidade local (*local reachability density*) como sendo:\n",
    "\n",
    "$$\n",
    "\\textrm{lrd}_k(A) = \\left[ \\frac{\\sum_{B \\in N_k(A)}  \\textrm{reachability-dist}_k(A,B)}{|N_k(A)|} \\right]^{-1}\n",
    "$$\n",
    "\n",
    "Essa dist√¢ncia de alcan√ßabilidade representa &ldquo;o qu√£o f√°cil em m√©dia&rdquo; √© chegar em $A$ sendo um dos vizinhos de $A$. A equa√ß√£o acima est√° elevada a $-1$ pois queremos que valores pequenos representem que √© &ldquo;f√°cil&rdquo; chegar em $A$ e valores grandes representem que √© &ldquo;dif√≠cil&rdquo; chegar em $A$.\n",
    "\n",
    "Finalmente, ap√≥s todas essas defini√ß√µes conseguimos definir o Fator de Discrep√¢ncia Local de $A$, que √© seu LOF:\n",
    "\n",
    "$$\n",
    "\\textrm{LOF}_A = \\frac{\\sum_{B \\in N_k(A)}  \\frac{\\textrm{lrd}_k(B)}{\\textrm{lrd}_k(A)}}{|N_k(A)|}\n",
    "$$\n",
    "\n",
    "O valor de $\\textrm{LOF}_A$ nos d√° pistas sobre a regi√£o onde o exemplo $A$ se encontra:\n",
    "\n",
    "-   Se o valor de $\\textrm{LOF}_A$ √© pr√≥ximo de 1: ent√£o $A$ est√° em uma regi√£o de densidade de pontos *similar* aos seus vizinhos;\n",
    "-   Se o valor de $\\textrm{LOF}_A$ √© maior de 1: ent√£o $A$ est√° em uma regi√£o de densidade de pontos *menor* que seus vizinhos;\n",
    "-   Se o valor de $\\textrm{LOF}_A$ √© menor de 1: ent√£o $A$ est√° em uma regi√£o de densidade de pontos *maior* que seus vizinhos.\n",
    "\n",
    "Infelizmente n√£o temos (ainda) v√≠deos do StatQuest sobre detec√ß√£o de valores an√¥malos&#x2026; mas temos este excelente [v√≠deo](https://www.youtube.com/watch?v=Xl7XVPyvO5U) do canal MachineLearningInterview e a [p√°gina da Wikip√©dia](https://en.wikipedia.org/wiki/Local_outlier_factor) em ingl√™s (que descreve o algoritmo de forma muito clara).\n",
    "\n",
    "O c√≥digo abaixo mostra como detectar outliers utilizando a implementa√ß√£o do LOF do `scikit-learn`. Primeiramente criamos o modelo. Veja que devemos passar o valor do n√∫mero de vizinhos que ser√£o considerados ao criar o modelo (√© o argumento `n_neighbors`). Aqui escolhemos 35. O valor padr√£o do `scikin-learn` √© 20. N√£o tem como dizer o melhor valor para seu conjunto de dados, cada caso √© um caso.\n",
    "\n",
    "Outro par√¢metro que passamos √© a fra√ß√£o de outliers que esperamos ter no nosso conjunto de dados (√© o argumento `contamination`). Aqui temos dados sint√©ticos e sabemos a fra√ß√£o de outliers. Caso n√£o saiba voc√™ dever√° dar um palpite ou usar o valor `\"auto\"` para este argumento e deixar que o algoritmo encontre esse valor para voc√™ (pode n√£o ser o ideal!). Outros hiperpar√¢metros podem ser conferidos na [documenta√ß√£o](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) do `scikit-learn`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "N_VIZINHOS = 35 \n",
    "# definimos o n√∫mero de vizinhos a serem consultados\n",
    "\n",
    "# aqui que criamos o modelo de Local Outlier Factor\n",
    "# o qual ir√° consultar o n√∫mero de vizinhos e a porcentagem de \n",
    "# dados que ser√£o considerados como contaminados\n",
    "modelo_lof = LocalOutlierFactor(\n",
    "    n_neighbors=N_VIZINHOS,\n",
    "    contamination=FRACAO_OUTLIERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O c√≥digo abaixo mostra como fazemos para detectar os outliers nos conjuntos de dados que geramos. Observe principalmente a linha onde chamamos o m√©todo `fit_predict`. N√£o √© apenas `fit` como est√°vamos acostumados!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=b.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HAZIEL~1\\AppData\\Local\\Temp/ipykernel_6580/3345454463.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Ajustamos o modelo aos dados e realizamos a previs√£o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmodelo_lof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprevisao\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelo_lof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\sklearn\\neighbors\\_lof.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0mlocal\u001b[0m \u001b[0moutlier\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \"\"\"\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontamination\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_algorithm_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;31m# If input is scalar raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    688\u001b[0m                     \u001b[1;34m\"Expected 2D array, got scalar array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=b.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "CORES = np.array([\"red\", \"blue\"])\n",
    "\n",
    "for n, df_norm in enumerate(df_norm):\n",
    "\n",
    "    # Ajustamos o modelo aos dados e realizamos a previs√£o\n",
    "    modelo_lof.fit(df_norm)\n",
    "    previsao = modelo_lof.fit_predict(df_norm)\n",
    "\n",
    "    fig, eixo = plt.subplots(figsize=(5, 5)) # determinamos o tamanho do gr√°fico que ser√° plotado\n",
    "\n",
    "    eixo.scatter(\n",
    "        df_norm[:, 0],\n",
    "        df_norm[:, 1],\n",
    "        marker=\".\",\n",
    "        s=4,\n",
    "        color=CORES[(previsao + 1) // 2], # agora determinamos a cor dos pontos correspondentes √†s anomalias e aos\n",
    "                                          # pontos \"normais\"\n",
    "    )\n",
    "\n",
    "    eixo.set_xlim(-8, 8)\n",
    "    eixo.set_ylim(-8, 8)\n",
    "    eixo.set_xticks(())\n",
    "    eixo.set_yticks(())\n",
    "    eixo.set_title(f\"Dataset {n}\", fontsize=10)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar o $\\textrm{LOF}$ de cada exemplo usando c√≠rculos! O c√≥digo abaixo √© o mesmo do anterior, por√©m com a parte que plota os os c√≠rculos de tamanho proporcional ao $\\textrm{LOF}$. Veja que quanto maior o $\\textrm{LOF}$ maior a chance do exemplo ser considerado um outlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lof = LocalOutlierFactor(\n",
    "    n_neighbors=N_VIZINHOS,\n",
    "    contamination=FRACAO_OUTLIERS,\n",
    ")\n",
    "\n",
    "for n, data_x in enumerate(datasets):\n",
    "\n",
    "    modelo_lof.fit(data_x)\n",
    "    previsao = modelo_lof.fit_predict(data_x)\n",
    "\n",
    "    fig, eixo = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "    eixo.scatter(\n",
    "        data_x[:, 0],\n",
    "        data_x[:, 1],\n",
    "        marker=\".\",\n",
    "        s=4,\n",
    "        color=CORES[(previsao + 1) // 2],\n",
    "    )\n",
    "\n",
    "    # plota os c√≠rculos!\n",
    "    # assim como mencionado na aula, os c√≠rculos servem para mostrar a \"magnitude\" de um outlier \n",
    "    # ou seja, quanto maior o c√≠rculo, maior a discrep√¢ncia dele perante os dados \"normais\"\n",
    "    X_lof = modelo_lof.negative_outlier_factor_\n",
    "    raios = (X_lof.max() - X_lof) / (X_lof.max() - X_lof.min())\n",
    "    eixo.scatter(\n",
    "        data_x[:, 0],\n",
    "        data_x[:, 1],\n",
    "        s=1000 * raios,\n",
    "        edgecolors=CORES[(previsao + 1) // 2],\n",
    "        facecolors=\"none\",\n",
    "    )\n",
    "\n",
    "    eixo.set_xlim(-8, 8)\n",
    "    eixo.set_ylim(-8, 8)\n",
    "    eixo.set_xticks(())\n",
    "    eixo.set_yticks(())\n",
    "    eixo.set_title(f\"Dataset {n}\", fontsize=10)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os c√≥digos desta se√ß√£o foram baseados [neste c√≥digo](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html) e [neste c√≥digo](https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html) da documenta√ß√£o do `scikit-learn`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo Isolation Forest (IF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Isolation Forest (IF) √© um algoritmo de detec√ß√£o de valores an√¥malos que utiliza uma floresta de √°rvores de decis√£o para realizar a sua detec√ß√£o.\n",
    "\n",
    "Este algoritmo usa conceitos do algoritmo de floresta aleat√≥ria que vimos durante o bloco de aprendizado supervisionado. A ideia por tr√°s deste algoritmo √© que <u>valores an√¥malos s√£o mais f√°ceis de serem isolados utilizando √°rvores de decis√£o do que valores que n√£o s√£o an√¥malos</u>.\n",
    "\n",
    "Vamos come√ßar do in√≠cio, antes de pensar em uma floresta de √°rvores de decis√£o, vamos pensar em apenas uma √°rvore de decis√£o e depois expandimos esse conceito para uma floresta.\n",
    "\n",
    "Diferentemente de uma √°rvore de decis√£o de um modelo supervisionado de aprendizado de m√°quina (onde nosso objetivo era prever um target), aqui nosso objetivo √© criar uma √°rvore de decis√£o que *isola* todos os pontos do nosso conjunto de dados. <u>*Isolar os pontos* significa que cada v√©rtice folha da nossa √°rvore cont√©m apenas um exemplo do nosso dataset OU apenas exemplos *iguais* do nosso dataset OU zero exemplos</u>. Quando essa condi√ß√£o for atingida, n√≥s terminamos de construir nossa √°rvore de decis√£o! üéâ Vamos chamar essa √°rvore de *√°rvore de isola√ß√£o*.\n",
    "\n",
    "Voc√™ certamente se recorda que em cada v√©rtice de decis√£o ou v√©rtice raiz de uma √°rvore de decis√£o n√≥s temos um condicional. Em uma √°rvore de decis√£o supervisionada, este condicional tem o objetivo de reduzir a impureza dos dados. Vale a pena rever o v√≠deo do [StatQuest](https://www.youtube.com/watch?v=_L39rN6gz7Y) sobre √°rvores de decis√£o se voc√™ n√£o se recorda do conceito de impureza.\n",
    "\n",
    "Em uma √°rvore de isola√ß√£o, n√≥s constru√≠mos os condicionais dos v√©rtices raiz e de decis√£o de maneira diferente: selecionamos um atributo de forma aleat√≥ria e, ap√≥s isso, selecionamos um valor de corte aleat√≥rio para separar os dados. Se, por exemplo, voc√™ tem um conjunto de dados com peso, altura e idade como atributos, ent√£o sua √°rvore de isola√ß√£o ir√° escolher um desses atributos de maneira aleat√≥ria. Digamos que escolheu o atributo idade. Depois disso, sua √°rvore de isola√ß√£o ir√° escolher um valor de corte aleat√≥rio. Digamos que este valor aleat√≥rio escolhido foi 27. Desta forma, este v√©rtice que acabamos de criar ter√° um condicional que checa se a idade √© maior que 27 anos e separa os dados em dois v√©rtices seguintes. Este processo √© repetido at√© que a condi√ß√£o de parada (linha sublinhada acima) for atingida.\n",
    "\n",
    "Como o algoritmo se chama floresta de isola√ß√£o e n√£o √°rvore de isola√ß√£o, voc√™ pode imaginar que esse processo de cria√ß√£o de √°rvores de isola√ß√£o √© repetido uma certa quantidade de vezes criando um comit√™ (ensemble) de √°rvores.\n",
    "\n",
    "Vamos visualizar! Na imagem abaixo n√≥s temos um conjunto de dados sint√©tico com dois atributos. Veja que conseguimos isolar o exemplo $x_j$ usando 4 cortes no conjunto de dados. Cada um desses cortes representa um condicional que foi visitado na √°rvore de isola√ß√£o (cada condicional corta o espa√ßo amostral em duas regi√µes de forma perpendicular √† uma das coordenadas).\n",
    "\n",
    "![img](https://upload.wikimedia.org/wikipedia/commons/f/ff/Isolating_an_Anomalous_Point.png)\n",
    "\n",
    "J√° na imagem abaixo n√≥s temos que para isolar o exemplo $x_i$ n√≥s precisamos de 13 cortes no conjunto de dados (isto √©, precisamos visitar 13 condicionais da nossa √°rvore de isola√ß√£o).\n",
    "\n",
    "![img](https://upload.wikimedia.org/wikipedia/commons/c/ce/Isolating_a_Non-Anomalous_Point.png)\n",
    "\n",
    "Qual desses dois exemplos ($x_j$ ou $x_i$) voc√™ acha que tem maior probabilidade de ser um valor an√¥malo? √â o $x_j$, pois este √© o mais f√°cil de ser isolado!\n",
    "\n",
    "Antes de seguir em frente na matem√°tica que usaremos para definir o que √© ou n√£o um valor an√¥malo usando a floresta de isola√ß√£o, vale a pena checar o excelente [v√≠deo](https://www.youtube.com/watch?v=cRzeotaFDwk) do MachineLearningInterview. Infelizmente n√£o temos ainda v√≠deos sobre detec√ß√£o de valores an√¥malos do StatQuest&#x2026;\n",
    "\n",
    "O primeiro passo para estimar se um certo exemplo $x$ √© um valor an√¥malo ou n√£o consiste em computar a profundidade m√©dia para isolar $x$ considerando todas as √°rvores na nossa floresta de isola√ß√£o. Essa profundidade √© computada justamente passando o exemplo $x$ em cada uma das √°rvores, anotando a profundidade em uma lista e, no final, tirando a m√©dia desses valores. Estatisticamente, esse valor √© a esperan√ßa da profundidade $h$ do exemplo $x$, logo √© representado por $E[h(x)]$.\n",
    "\n",
    "Agora precisamos computar a profundidade m√©dia $c$ para isolar *qualquer* exemplo pertencente ao nosso conjunto de dados. Para isso podemos calcular a esperan√ßa da profundidade de *todos* os exemplos do nosso conjunto de dados e tirar a m√©dia destes valores. Existe uma forma de estimar esse valor $c$ usando a considera√ß√£o que nossas √°rvores de isola√ß√£o s√£o [√°rvores bin√°rias de busca](https://en.wikipedia.org/wiki/Binary_search_tree). Sabendo que $\\gamma=0.5772156649$ (constante de Euler-Mascheroni) o valor de $c$ para um conjunto √°rvores induzidas a partir de um conjunto de dados de tamanho $n>2$ pode ser estimado por:\n",
    "\n",
    "$$\n",
    "c(n)=2\\left[\\ln(n-1) + \\gamma-\\frac{(n-1)}{n}\\right]\n",
    "$$\n",
    "\n",
    "Finalmente, tento em m√£os $E[h(x)]$ e $c(n)$, podemos calcular uma nota $s$ para nosso exemplo $x$ da seguinte maneira:\n",
    "\n",
    "$$\n",
    "s(x,n)=2^{-\\frac{E[h(x)]}{c(n)}}\n",
    "$$\n",
    "\n",
    "Tendo o valor de $s$ n√≥s podemos fazer infer√™ncias:\n",
    "\n",
    "-   Se $s$ √© perto de 1, ent√£o $x$ √© muito provavelmente um valor an√¥malo;\n",
    "-   Se $s$ √© menor que 0,5, ent√£o $x$ muito provavelmente n√£o √© um valor an√¥malo;\n",
    "-   Se $s$ √© menor que 1 e maior que 0,5 √© necess√°rio definir um valor de corte at√© onde aceitamos considerar $x$ um valor an√¥malo;\n",
    "-   Se todos os valores $s$ s√£o pr√≥ximos de 0,5, ent√£o √© seguro assumir que n√£o existem valores an√¥malos no conjunto de dados.\n",
    "\n",
    "Muito bem, agora que sabemos a matem√°tica por tr√°s do algoritmo, vamos ver como us√°-lo em Python. Usaremos a classe `IsolationForest` do `scikit-learn`. Como sempre, √© bom checar a [documenta√ß√£o](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html).\n",
    "\n",
    "Primeiramente criamos o modelo. Novamente estamos passando a fra√ß√£o de outliers para o hiperpar√¢metro `contamination`. Se n√£o souber ou quiser computar isso automaticamente, basta eliminar essa linha ou passar o valor `\"auto\"` para esse hiperpar√¢metro.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "CORES = np.array([\"red\", \"blue\"])\n",
    "COM_BORDA_DE_PREVISAO = False # mude para True para ver a borda de previs√£o\n",
    "\n",
    "# aqui que criamos o modelo de Isolation Forest\n",
    "modelo_if = IsolationForest(\n",
    "    contamination=FRACAO_OUTLIERS,\n",
    "    random_state=SEMENTE_ALEATORIA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora treinamos o modelo usando o m√©todo `fit` e realizamos a previs√£o com o m√©todo `predict`. Como o modelo de floresta de isola√ß√£o tem o m√©todo `predict` ele pode ser utilizado tanto para detec√ß√£o de outliers quanto para detec√ß√£o de novidade!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, data_x in enumerate(datasets):\n",
    "\n",
    "    # Ajustamos o modelo aos dados e realizamos a previs√£o\n",
    "    modelo_if.fit(data_x)\n",
    "    previsao = modelo_if.predict(data_x)\n",
    "\n",
    "    fig, eixo = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "    eixo.scatter(\n",
    "        data_x[:, 0],\n",
    "        data_x[:, 1],\n",
    "        s=4,\n",
    "        color=CORES[(previsao + 1) // 2],\n",
    "    )\n",
    "\n",
    "    eixo.set_xlim(-8, 8)\n",
    "    eixo.set_ylim(-8, 8)\n",
    "    eixo.set_xticks(())\n",
    "    eixo.set_yticks(())\n",
    "    eixo.set_title(f\"Dataset {n}\", fontsize=10)\n",
    "\n",
    "    # plota a borda entre as regi√µes de outlier/inlier\n",
    "    if COM_BORDA_DE_PREVISAO:\n",
    "        xx, yy = np.meshgrid(\n",
    "            np.linspace(-8, 8, 150),\n",
    "            np.linspace(-8, 8, 150),\n",
    "        )\n",
    "        Z = modelo_if.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        eixo.contour(xx, yy, Z, levels=[0], linewidths=2, colors=\"black\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O c√≥digo desta se√ß√£o foi baseado [neste c√≥digo](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html) da documenta√ß√£o do `scikit-learn`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando com o dataset de diamantes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar o que aprendemos com o dataset de diamantes. Primeiramente vamos carregar os dados. Como √© um aprendizado n√£o supervisionado, n√£o iremos utilizar o target.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TAMANHO_TESTE = 0.1\n",
    "SEMENTE_ALEATORIA = 61455\n",
    "DATASET_NAME = \"diamonds\"\n",
    "FEATURES = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
    "\n",
    "df = sns.load_dataset(DATASET_NAME)\n",
    "X = df.reindex(FEATURES, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como iremos usar um algoritmo baseado em dist√¢ncias (LOF), ent√£o √© uma boa pr√°tica normalizar os dados!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalizador = MinMaxScaler()\n",
    "normalizador.fit(X)\n",
    "X_norm = normalizador.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para melhorar a visualiza√ß√£o, vamos usar um PCA tamb√©m!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_norm)\n",
    "X_pca = pca.transform(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos tentar usar o LOF nos nossos dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precisamos indicar a fra√ß√£o de outliers, vamos estimar que seja 1%\n",
    "FRACAO_OUTLIERS = 0.01\n",
    "\n",
    "# precisamos tamb√©m indicar o n√∫mero de vizinhos que ser√£o considerados\n",
    "N_VIZINHOS = 35\n",
    "\n",
    "CORES = np.array([\"red\", \"blue\"])\n",
    "\n",
    "modelo_lof = LocalOutlierFactor(\n",
    "    n_neighbors=N_VIZINHOS,\n",
    "    contamination=FRACAO_OUTLIERS,\n",
    ")\n",
    "\n",
    "modelo_lof.fit(X_pca)\n",
    "previsao = modelo_lof.fit_predict(X_pca)\n",
    "\n",
    "fig, eixo = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "eixo.scatter(\n",
    "    X_pca[:, 0],\n",
    "    X_pca[:, 1],\n",
    "    s=1,\n",
    "    color=CORES[(previsao + 1) // 2],\n",
    ")\n",
    "\n",
    "eixo.set_xlabel(\"Componente principal 1\")\n",
    "eixo.set_ylabel(\"Componente principal 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos tentar usar o Isolation Forest agora.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precisamos indicar a fra√ß√£o de outliers, vamos estimar que seja 1%\n",
    "FRACAO_OUTLIERS = 0.01\n",
    "\n",
    "CORES = np.array([\"red\", \"blue\"])\n",
    "\n",
    "modelo_if = IsolationForest(\n",
    "    contamination=FRACAO_OUTLIERS,\n",
    "    random_state=SEMENTE_ALEATORIA,\n",
    ")\n",
    "\n",
    "# Ajustamos o modelo aos dados e realizamos a previs√£o\n",
    "modelo_if.fit(X_pca)\n",
    "previsao = modelo_if.predict(X_pca)\n",
    "\n",
    "fig, eixo = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "eixo.scatter(\n",
    "    X_pca[:, 0],\n",
    "    X_pca[:, 1],\n",
    "    s=1,\n",
    "    color=CORES[(previsao + 1) // 2],\n",
    ")\n",
    "\n",
    "eixo.set_xlabel(\"Componente principal 1\")\n",
    "eixo.set_ylabel(\"Componente principal 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voc√™ pode remover os valores an√¥malos (processo chamado de *data cleaning*) da seguinte maneira:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic = previsao == 1\n",
    "X_clean = X[logic]\n",
    "\n",
    "print(X.shape)\n",
    "print(X_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como exerc√≠cio, escolha um algoritmo de aprendizado de m√°quina supervisionado ($k$‚Äã-vizinhos mais pr√≥ximos, √°rvore de decis√£o, floresta aleat√≥ria ou qualquer outro de sua prefer√™ncia) e treine um modelo usando os dados brutos (sem eliminar os outliers) e os dados limpos (eliminando os outliers). Observe se a performance melhorou, piorou ou permaneceu constante ap√≥s a limpeza.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuidado: valores an√¥malos n√£o significam valores que devem ser descartados!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste notebook n√≥s identificamos valores an√¥malos em diversos conjuntos de dados. Na se√ß√£o anterior, o exerc√≠cio foi justamente testar um algoritmo de aprendizado de m√°quina com e sem a elimina√ß√£o de outliers.\n",
    "\n",
    "√â importante deixar claro que <u>valores an√¥malos n√£o s√£o necessariamente valores que devem ser descartados</u>! Existem diversos valores an√¥malos de alt√≠ssimo interesse cient√≠fico! Imagina se tiv√©ssemos descartado os valores de condutividade de supercondutores apenas e t√£o somente pois eram an√¥malos com rela√ß√£o ao conhecimento cient√≠fico da √©poca?\n",
    "\n",
    "Algoritmos de identifica√ß√£o de valores an√¥malos nos convidam a explorar esses valores com cuidado em busca de pistas sobre o que levou eles a serem an√¥malos. Um valor an√¥malo pode ser apenas um erro de digita√ß√£o, mas tamb√©m pode ser uma patente que ir√° te render milh√µes!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando suas habilidades e avan√ßando nos seus estudos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os links abaixo s√£o de reposit√≥rios de datasets curados para detec√ß√£o de outliers. Use eles para testar suas habilidades.\n",
    "\n",
    "-   [https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OPQMVF](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OPQMVF)\n",
    "\n",
    "-   [https://ir.library.oregonstate.edu/concern/datasets/47429f155](https://ir.library.oregonstate.edu/concern/datasets/47429f155)\n",
    "\n",
    "Se voc√™ quiser avan√ßar nos seus estudos de detec√ß√£o de valores an√¥malos, veja esse [reposit√≥rio](https://github.com/yzhao062/anomaly-detection-resources) do GitHub com diversos materiais sobre esse tema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XKCD relevante\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://imgs.xkcd.com/comics/boyfriend.png)\n",
    "\n",
    "`Imagem: Boyfriend (XKCD) dispon√≠vel em https://xkcd.com/539`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refer√™ncias e leitura adicional\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  [https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/](https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/)\n",
    "2.  [https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html)\n",
    "3.  [https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_outlier_detection_bench.html](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_outlier_detection_bench.html)\n",
    "4.  [https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html](https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html)\n",
    "5.  [https://scikit-learn.org/stable/auto_examples/ensemble/plot_isolation_forest.html](https://scikit-learn.org/stable/auto_examples/ensemble/plot_isolation_forest.html)\n",
    "6.  [https://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf](https://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf)\n",
    "7.  [https://www.youtube.com/watch?v=XAkXUSxJNlM](https://www.youtube.com/watch?v=XAkXUSxJNlM)\n",
    "8.  [https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf)\n",
    "9.  [https://github.com/yzhao062/anomaly-detection-resources](https://github.com/yzhao062/anomaly-detection-resources)\n",
    "10. [https://github.com/yzhao062/pyod](https://github.com/yzhao062/pyod)\n",
    "11. [V√≠deo sobre detec√ß√£o de valores an√¥malos do StatQuest](https://www.youtube.com/watch?v=dQw4w9WgXcQ)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
