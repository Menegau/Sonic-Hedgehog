{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9adabca8-d0b4-4cbc-b3c8-cdcd6399f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042552e6-318f-420a-8787-b49fdb067b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adelie' 'Chinstrap' 'Gentoo']\n"
     ]
    }
   ],
   "source": [
    "df = sns.load_dataset('penguins')\n",
    "dfcopia = df.copy()\n",
    "dfcopia = dfcopia.dropna(axis=0)\n",
    "especies = dfcopia['species'].unique()\n",
    "print(especies)\n",
    "\n",
    "dfcopia['specie numerica'] = 0\n",
    "\n",
    "i = 0\n",
    "for pinguin in dfcopia['species']:\n",
    "    #print(pinguin)\n",
    "    if pinguin == 'Adelie':\n",
    "        dfcopia['specie numerica'].iloc[i] = 1\n",
    "        i += 1\n",
    "    elif pinguin == 'Chinstrap':\n",
    "        dfcopia['specie numerica'].iloc[i] = 2\n",
    "        i += 1\n",
    "    elif pinguin == 'Gentoo':\n",
    "        dfcopia['specie numerica'].iloc[i] = 3\n",
    "        i += 1\n",
    "    #print(dfcopia['species'].iloc[i-1],dfcopia['specie numerica'].iloc[i-1])\n",
    "\n",
    "features_numericos = [\"bill_length_mm\",\"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "df_numericos = dfcopia[features_numericos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf76afa-c1c5-4453-ba6d-263f0c4ddfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(df_numericos)\n",
    "X_norm = sc.transform(df_numericos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40c998a-4f21-4dd1-83f5-482b570b449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0    Adelie  Torgersen            39.1           18.7              181.0   \n",
      "1    Adelie  Torgersen            39.5           17.4              186.0   \n",
      "2    Adelie  Torgersen            40.3           18.0              195.0   \n",
      "4    Adelie  Torgersen            36.7           19.3              193.0   \n",
      "5    Adelie  Torgersen            39.3           20.6              190.0   \n",
      "..      ...        ...             ...            ...                ...   \n",
      "338  Gentoo     Biscoe            47.2           13.7              214.0   \n",
      "340  Gentoo     Biscoe            46.8           14.3              215.0   \n",
      "341  Gentoo     Biscoe            50.4           15.7              222.0   \n",
      "342  Gentoo     Biscoe            45.2           14.8              212.0   \n",
      "343  Gentoo     Biscoe            49.9           16.1              213.0   \n",
      "\n",
      "     body_mass_g     sex  specie numerica  \n",
      "0         3750.0    Male                1  \n",
      "1         3800.0  Female                1  \n",
      "2         3250.0  Female                1  \n",
      "4         3450.0  Female                1  \n",
      "5         3650.0    Male                1  \n",
      "..           ...     ...              ...  \n",
      "338       4925.0  Female                3  \n",
      "340       4850.0  Female                3  \n",
      "341       5750.0    Male                3  \n",
      "342       5200.0  Female                3  \n",
      "343       5400.0    Male                3  \n",
      "\n",
      "[333 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dfcopia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe7b653b-5f24-46a6-aedd-88ce4b5f0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]\n",
    "TARGET = [\"specie numerica\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78760660-9cb1-4fdb-8d2d-fc601d590973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler() #Definindo o normalizador\n",
    "X_norm = scaler.fit_transform(dfcopia[FEATURES].values) #Normalizando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7eb763-c17f-4c72-b009-84aefbafe80a",
   "metadata": {},
   "source": [
    "Normalizamos os dados a fim de realizarmos os PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ea0bdb1-ef49-476a-9e7b-d7201cb19049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bill_length_mm  bill_depth_mm  flipper_length_mm  specie numerica\n",
      "0        0.254545       0.666667           0.152542                1\n",
      "1        0.269091       0.511905           0.237288                1\n",
      "2        0.298182       0.583333           0.389831                1\n",
      "3        0.167273       0.738095           0.355932                1\n",
      "4        0.261818       0.892857           0.305085                1\n",
      "5        0.247273       0.559524           0.152542                1\n",
      "6        0.258182       0.773810           0.389831                1\n",
      "7        0.327273       0.535714           0.169492                1\n",
      "8        0.236364       0.964286           0.322034                1\n",
      "9        0.090909       0.952381           0.440678                1\n"
     ]
    }
   ],
   "source": [
    "df_norm = pd.DataFrame(X_norm,columns = FEATURES) #Criando o DataFrame a partir com dados normalizados, que é um array de numpy\n",
    "df_norm = pd.concat([df_norm,pd.Series(dfcopia['specie numerica']).reset_index(drop=True)],axis=1) #Concatenando a coluna 'price' ao DataFrame\n",
    "print(df_norm.head(10)) #Exibindo as 10 primeiras linhas do dataset normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fca697c-c91c-4be9-a177-74e4d3adb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "X = df_norm[FEATURES] #Definindo o X como as features\n",
    "y = df_norm['specie numerica']  #Definindo o y como o target\n",
    "\n",
    "pca = PCA(n_components=3) #Calculando o PCA para três componentes\n",
    "pca.fit(X)                #Ajustando o PCA\n",
    "X_pca = pca.transform(X)  #Realizando o PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15e3cc88-7bef-4938-99c4-31343a94fb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(pca.explained_variance_ratio_)) #Calculando a variância explicada acumulada para as três componentes principais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2e91fb-c28a-49b4-81e2-ba92247957ea",
   "metadata": {},
   "source": [
    "É notável que a variância é muito alta, então devemos dividir o dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b532a06f-4d26-4bec-9c01-c844cc2bc494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( #Chamando a função train_test_split, atribuindo os valores nas variáveis a esquerda da igualdade\n",
    "    X_pca,                                           #Dados das componentes principais do PCA\n",
    "    y,                                               #Dados do target\n",
    "    test_size=0.2,                                   #Tamanho do conjunto de teste\n",
    "    random_state=61)                                 #Semente aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57883883-3ff2-475d-9fcd-67fb3177b3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PC1       PC2       PC3  specie numerica\n",
      "0 -0.417304 -0.047414  0.056515                1\n",
      "1 -0.263773 -0.135362  0.062671                1\n",
      "2 -0.185816 -0.033273 -0.050103                1\n",
      "3 -0.355020 -0.010007 -0.164409                1\n",
      "4 -0.437199  0.154948 -0.125524                1\n",
      "5 -0.359367 -0.131234  0.090425                1\n",
      "6 -0.312010  0.081679 -0.143602                1\n",
      "7 -0.298952 -0.093937  0.137469                1\n",
      "8 -0.477330  0.194728 -0.178856                1\n",
      "9 -0.451868  0.116134 -0.347823                1\n",
      "                    PC1     PC2     PC3  specie numerica\n",
      "PC1              1.0000 -0.0000  0.0000           0.9474\n",
      "PC2             -0.0000  1.0000  0.0000           0.0304\n",
      "PC3              0.0000  0.0000  1.0000           0.1284\n",
      "specie numerica  0.9474  0.0304  0.1284           1.0000\n"
     ]
    }
   ],
   "source": [
    "df_norm_treino = pd.DataFrame(X_pca,columns=['PC1', 'PC2', 'PC3']) #Define as colunas das PC em um dataframe, utilizando os dados do X_pca\n",
    "df_norm_treino['specie numerica'] = y                                        #Adiciona a coluna preço, com os dados de y\n",
    "print(df_norm_treino.head(10))                                     #Exibe as 10 primeiras linhas do dataset\n",
    "corrmat = df_norm_treino.corr()                                    #Cálculo da correlação\n",
    "print(round(corrmat,4))                                          #Exibe a correlação com 4 casas decimais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f3a402-bf8e-461f-b247-ed74203d1019",
   "metadata": {},
   "source": [
    "Com isso, criamos um novo dataset com dimensionalidade reduzida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a07a246-485e-475c-888e-c58112b45ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# cria o modelo\n",
    "modelo_linear = LinearRegression()\n",
    "\n",
    "# treina o modelo\n",
    "modelo_linear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5b9d5aa-aca2-48e4-84d4-355a85a0e372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo linear foi de 0.27231019633925413.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_verdadeiro = y_test\n",
    "y_previsao = modelo_linear.predict(X_test)\n",
    "\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False) #Cálculo do RMSE\n",
    "\n",
    "print(f\"O RMSE do modelo linear foi de {RMSE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edf478d7-f125-46b1-9619-87693000be4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=61454)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# cria o modelo\n",
    "SEMENTE_ALEATORIA = 61454\n",
    "modelo_rf = RandomForestRegressor(random_state=SEMENTE_ALEATORIA)\n",
    "\n",
    "# treina o modelo\n",
    "modelo_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fc3480d-c7e5-4ca3-b3b3-24e028ea1809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo árvore de decisão foi de 0.19409952824690646.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_verdadeiro = y_test\n",
    "y_previsao = modelo_rf.predict(X_test)\n",
    "\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "\n",
    "print(f\"O RMSE do modelo árvore de decisão foi de {RMSE}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920012f-ad8d-418a-82ee-026e9cdecfa9",
   "metadata": {},
   "source": [
    "O RMSE obtido significa que o erro é de 19%, aproximadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31927943-fc68-4062-9b2c-0dc046f78b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
