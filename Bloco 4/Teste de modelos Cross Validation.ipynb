{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe41921-c7cc-4b4f-8d16-a658e5ccebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b701636-a163-43d8-b44d-bb56a03c308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adelie' 'Chinstrap' 'Gentoo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv\\ilumpy\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "df = sns.load_dataset('penguins')\n",
    "dfcopia = df.copy()\n",
    "dfcopia = dfcopia.dropna(axis=0)\n",
    "especies = dfcopia['species'].unique()\n",
    "print(especies)\n",
    "\n",
    "dfcopia['specie numerica'] = 0\n",
    "\n",
    "i = 0\n",
    "for pinguin in dfcopia['species']:\n",
    "    #print(pinguin)\n",
    "    if pinguin == 'Adelie':\n",
    "        dfcopia['specie numerica'].iloc[i] = 1\n",
    "        i += 1\n",
    "    elif pinguin == 'Chinstrap':\n",
    "        dfcopia['specie numerica'].iloc[i] = 2\n",
    "        i += 1\n",
    "    elif pinguin == 'Gentoo':\n",
    "        dfcopia['specie numerica'].iloc[i] = 3\n",
    "        i += 1\n",
    "    #print(dfcopia['species'].iloc[i-1],dfcopia['specie numerica'].iloc[i-1])\n",
    "\n",
    "features_numericos = [\"bill_length_mm\",\"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "df_numericos = dfcopia[features_numericos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb5dba4-6370-46a4-b032-e8941ed8046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(df_numericos)\n",
    "X_norm = sc.transform(df_numericos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d51e56e-e469-4a56-9ca8-a071046250d3",
   "metadata": {},
   "source": [
    "# Testando Modelos Diferentes\n",
    "Testaremos a validação cruzada com o modelo de floresta aleatória.\n",
    "Para esse teste, modifiquei 3 dos hiperparâmetros da floresta aleatória: *Número de folhas*, *Número de árvores* e o *Número de profundidade*. Para cada um dos hiperparâmetros, escolhi 3 números. Dessa forma, o número total de modelos diferentes é igual a 3³, ou 27. Também estipulei o número de k-fold para 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35cb0294-3f25-4e9a-acb3-376fd3ee705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Carregando os dados e definindo parâmetros:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TAMANHO_TESTE = 0.1\n",
    "SEMENTE_ALEATORIA = 61455\n",
    "FEATURES = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "TARGET = [\"specie numerica\"]\n",
    "\n",
    "df = dfcopia\n",
    "\n",
    "indices = df.index\n",
    "indices_treino, indices_teste = train_test_split(\n",
    "    indices, test_size = TAMANHO_TESTE, random_state = SEMENTE_ALEATORIA\n",
    ")\n",
    "\n",
    "df_treino = df.loc[indices_treino]\n",
    "df_teste = df.loc[indices_teste]\n",
    "\n",
    "# o .values utiliza apenas os valores, em forma de array\n",
    "x_treino = df_treino.reindex(FEATURES, axis=1).values\n",
    "y_treino = df_treino.reindex(TARGET, axis=1).values\n",
    "x_teste = df_teste.reindex(FEATURES, axis=1).values\n",
    "y_teste = df_teste.reindex(TARGET, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736a71a5-936a-4e11-b65f-21fece4d5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Importando bibliotecas necessárias\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dc4cf5f-54f3-4e41-96c5-13080d813137",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "10 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99997102 0.93950786 0.99724105 0.9782757  0.96864125 0.99692537\n",
      " 0.99999975 0.99059597 0.96873463 0.99615739 0.93284281 0.99423925\n",
      " 0.95221341 0.98808175 0.93522041]\n",
      "A média dos scores é de: 0.9759098419911065\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "100 número de árvores,\n",
      "10 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99998298 0.93827879 0.99759013 0.96693982 0.96084947 0.99773394\n",
      " 0.99997733 0.98750996 0.96835683 0.996556   0.93365366 0.99423732\n",
      " 0.96440144 0.98833949 0.93177798]\n",
      "A média dos scores é de: 0.975079008517195\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "10 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99999919 0.93461165 0.99540958 0.97087671 0.96599957 0.99756373\n",
      " 0.99999905 0.98442353 0.96998977 0.99767374 0.93432208 0.99220746\n",
      " 0.96269077 0.98524628 0.92961366]\n",
      "A média dos scores é de: 0.9747084513221179\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "10 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99997102 0.93950786 0.99716054 0.97724835 0.96864125 0.99692537\n",
      " 0.99999975 0.99060413 0.96873463 0.99615739 0.93284281 0.99423925\n",
      " 0.95221341 0.98952533 0.93522041]\n",
      "A média dos scores é de: 0.9759327674218364\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "100 número de árvores,\n",
      "10 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99999164 0.93827879 0.99767294 0.96634332 0.96084947 0.99773394\n",
      " 0.99997733 0.9876755  0.96764162 0.9965327  0.93368562 0.99389179\n",
      " 0.96440144 0.98922903 0.93207192]\n",
      "A média dos scores é de: 0.9750651366013713\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "10 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99999924 0.934609   0.99552046 0.97102686 0.96571611 0.99760945\n",
      " 0.99999906 0.98458129 0.96968585 0.99763906 0.93432497 0.99211446\n",
      " 0.96294169 0.98616911 0.92969611]\n",
      "A média dos scores é de: 0.974775513373091\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "10 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99997102 0.93950786 0.99716054 0.97724835 0.96864125 0.99692537\n",
      " 0.99999975 0.99060413 0.96873463 0.99615739 0.93284281 0.99423925\n",
      " 0.95221341 0.98952533 0.93522041]\n",
      "A média dos scores é de: 0.9759327674218364\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "100 número de árvores,\n",
      "10 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99999164 0.93827879 0.99767294 0.96634332 0.96084947 0.99773394\n",
      " 0.99997733 0.9876755  0.96764162 0.9965327  0.93368562 0.99389179\n",
      " 0.96440144 0.98922903 0.93207192]\n",
      "A média dos scores é de: 0.9750651366013713\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "10 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99999924 0.934609   0.99552046 0.97102686 0.96571611 0.99760945\n",
      " 0.99999906 0.98458129 0.96968585 0.99763906 0.93432497 0.99211446\n",
      " 0.96294169 0.98616911 0.92969611]\n",
      "A média dos scores é de: 0.974775513373091\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "15 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99997315 0.93951163 0.997436   0.98146181 0.96858068 0.99519003\n",
      " 1.         0.99229359 0.96732154 0.99538144 0.93284281 0.99437363\n",
      " 0.95271111 0.98899686 0.9351076 ]\n",
      "A média dos scores é de: 0.9760787912900178\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "100 número de árvores,\n",
      "15 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99998506 0.93829061 0.99774118 0.96960018 0.96148835 0.9958622\n",
      " 0.99997753 0.99026009 0.96738798 0.99623639 0.93365366 0.9943182\n",
      " 0.96383492 0.98884853 0.93170143]\n",
      "A média dos scores é de: 0.9752790875503735\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "15 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99999971 0.93461167 0.99540385 0.9725219  0.96601483 0.99663488\n",
      " 0.99999942 0.98656612 0.96855775 0.99765325 0.93431588 0.9923774\n",
      " 0.96219005 0.98629011 0.92996988]\n",
      "A média dos scores é de: 0.9748737797122728\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "15 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99997368 0.93951163 0.9974269  0.98148485 0.9704     0.99471698\n",
      " 1.         0.99230476 0.96582818 0.99538144 0.93284281 0.99437363\n",
      " 0.95271111 0.99048485 0.93571908]\n",
      "A média dos scores é de: 0.9762106603680473\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "100 número de árvores,\n",
      "15 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99999342 0.9382907  0.99783626 0.97007576 0.96250909 0.99563881\n",
      " 0.99997753 0.99040635 0.96589691 0.99624742 0.93368562 0.99401099\n",
      " 0.96383492 0.98979545 0.93226718]\n",
      "A média dos scores é de: 0.9753644269482759\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "15 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.9999998  0.93460901 0.99551766 0.97297932 0.965764   0.99641838\n",
      " 0.99999944 0.98702419 0.96780619 0.99762667 0.93432087 0.99238989\n",
      " 0.96247575 0.98740144 0.93029103]\n",
      "A média dos scores é de: 0.9749749088371069\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "15 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99997368 0.93951163 0.9974269  0.98148485 0.9704     0.99471698\n",
      " 1.         0.99230476 0.96582818 0.99538144 0.93284281 0.99437363\n",
      " 0.95271111 0.99048485 0.93571908]\n",
      "A média dos scores é de: 0.9762106603680473\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "100 número de árvores,\n",
      "15 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99999342 0.9382907  0.99783626 0.97007576 0.96250909 0.99563881\n",
      " 0.99997753 0.99040635 0.96589691 0.99624742 0.93368562 0.99401099\n",
      " 0.96383492 0.98979545 0.93226718]\n",
      "A média dos scores é de: 0.9753644269482759\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "15 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.9999998  0.93460901 0.99551766 0.97297932 0.965764   0.99641838\n",
      " 0.99999944 0.98702419 0.96780619 0.99762667 0.93432087 0.99238989\n",
      " 0.96247575 0.98740144 0.93029103]\n",
      "A média dos scores é de: 0.9749749088371069\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "30 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99997315 0.93951163 0.997436   0.98146181 0.96858068 0.99519003\n",
      " 1.         0.99229359 0.96732154 0.99538144 0.93284281 0.99437363\n",
      " 0.95271111 0.98899686 0.9351076 ]\n",
      "A média dos scores é de: 0.9760787912900178\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "100 número de árvores,\n",
      "30 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99998506 0.93829061 0.99774118 0.96960018 0.96148835 0.9958622\n",
      " 0.99997753 0.99026009 0.96738798 0.99623639 0.93365366 0.9943182\n",
      " 0.96383492 0.98884853 0.93170143]\n",
      "A média dos scores é de: 0.9752790875503735\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "30 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99999971 0.93461167 0.99540385 0.9725219  0.96601483 0.99663488\n",
      " 0.99999942 0.98656612 0.96855775 0.99765325 0.93431588 0.9923774\n",
      " 0.96219005 0.98629011 0.92996988]\n",
      "A média dos scores é de: 0.9748737797122728\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "30 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99997368 0.93951163 0.9974269  0.98148485 0.9704     0.99471698\n",
      " 1.         0.99230476 0.96582818 0.99538144 0.93284281 0.99437363\n",
      " 0.95271111 0.99048485 0.93571908]\n",
      "A média dos scores é de: 0.9762106603680473\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "100 número de árvores,\n",
      "30 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99999342 0.9382907  0.99783626 0.97007576 0.96250909 0.99563881\n",
      " 0.99997753 0.99040635 0.96589691 0.99624742 0.93368562 0.99401099\n",
      " 0.96383492 0.98979545 0.93226718]\n",
      "A média dos scores é de: 0.9753644269482759\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "30 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.9999998  0.93460901 0.99551766 0.97297932 0.965764   0.99641838\n",
      " 0.99999944 0.98702419 0.96780619 0.99762667 0.93432087 0.99238989\n",
      " 0.96247575 0.98740144 0.93029103]\n",
      "A média dos scores é de: 0.9749749088371069\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "30 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99997368 0.93951163 0.9974269  0.98148485 0.9704     0.99471698\n",
      " 1.         0.99230476 0.96582818 0.99538144 0.93284281 0.99437363\n",
      " 0.95271111 0.99048485 0.93571908]\n",
      "A média dos scores é de: 0.9762106603680473\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "100 número de árvores,\n",
      "30 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.99999342 0.9382907  0.99783626 0.97007576 0.96250909 0.99563881\n",
      " 0.99997753 0.99040635 0.96589691 0.99624742 0.93368562 0.99401099\n",
      " 0.96383492 0.98979545 0.93226718]\n",
      "A média dos scores é de: 0.9753644269482759\n",
      "\n",
      "Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "30 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [0.9999998  0.93460901 0.99551766 0.97297932 0.965764   0.99641838\n",
      " 0.99999944 0.98702419 0.96780619 0.99762667 0.93432087 0.99238989\n",
      " 0.96247575 0.98740144 0.93029103]\n",
      "A média dos scores é de: 0.9749749088371069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----- Aqui o score estipulado é o R².\n",
    "from itertools import product\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "NUM_ARVORES = [50, 100, 1000]\n",
    "NUM_FOLHAS = [10, 15, 30]\n",
    "NUM_PROFUNDIDADE = [5, 10, 15]\n",
    "NUM_FOLDS = 15\n",
    "NUM_CPU_CORES = 4\n",
    "\n",
    "for n_folhas, n_profundidade, n_arvores in product(\n",
    "    NUM_FOLHAS, NUM_PROFUNDIDADE, NUM_ARVORES\n",
    "):\n",
    "    modelo_rf = RandomForestRegressor(\n",
    "        n_estimators=n_arvores,\n",
    "        max_leaf_nodes=n_folhas,\n",
    "        max_depth=n_profundidade,\n",
    "        random_state=SEMENTE_ALEATORIA,\n",
    "        n_jobs= NUM_CPU_CORES,\n",
    "    )\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "    #modelo_rf.fit(x_treino, y_treino)\n",
    "    modelo_rf,\n",
    "    x_treino,\n",
    "    y_treino.ravel(),\n",
    "    cv=NUM_FOLDS,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Aplicando a métrica de erro R² para os seguintes hiperparâmetros: \\n\"\n",
    "        f\"{n_arvores} número de árvores,\\n\"\n",
    "        f\"{n_folhas} número de folhas e\\n\"\n",
    "        f\"{n_profundidade} número de profundidade\\n\"\n",
    "        f\"temos que:\\n\"\n",
    "        f\"Os scores foram de: {scores}\\n\"\n",
    "        f\"A média dos scores é de: {scores.mean()}\"\n",
    "        f\"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28ed928b-8d98-4399-a796-3fcd72b70a13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "10 número de árvores,\n",
      "10 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.02237601 -0.2236068  -0.07130164 -0.13027308 -0.11401754 -0.06761863\n",
      " -0.00062619 -0.08065543 -0.17175564 -0.06992059 -0.2236068  -0.09350066\n",
      " -0.17897326 -0.13691718 -0.18353259]\n",
      "A média dos scores é de: -0.11791213484805145\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "10 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.00469345 -0.22808605 -0.03434312 -0.11974155 -0.13132901 -0.05340153\n",
      " -0.00046737 -0.08605622 -0.15081629 -0.05287245 -0.22405357 -0.07240359\n",
      " -0.19398953 -0.08869072 -0.21682839]\n",
      "A média dos scores é de: -0.11051818925329199\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "10 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.00078683 -0.23713705 -0.04429903 -0.13864116 -0.13674881 -0.04753564\n",
      " -0.00091771 -0.1107541  -0.14775806 -0.04113825 -0.22157222 -0.08420934\n",
      " -0.17140891 -0.09867853 -0.22601707]\n",
      "A média dos scores é de: -0.11384018013077227\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "10 número de árvores,\n",
      "10 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.02237601 -0.2236068  -0.07130164 -0.13027308 -0.11401754 -0.06761863\n",
      " -0.00062619 -0.08065543 -0.17175564 -0.06992059 -0.2236068  -0.09350066\n",
      " -0.17897326 -0.12609161 -0.18353259]\n",
      "A média dos scores é de: -0.11719042963275701\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "10 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.00469345 -0.22808605 -0.03484061 -0.12254015 -0.13132901 -0.05340153\n",
      " -0.00046737 -0.08601887 -0.15081629 -0.05287245 -0.22405357 -0.07240359\n",
      " -0.19398953 -0.08314616 -0.21682839]\n",
      "A média dos scores é de: -0.11036580064478775\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "10 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.00075962 -0.23714185 -0.04376077 -0.1382833  -0.13731767 -0.04708755\n",
      " -0.00091388 -0.11019181 -0.14850436 -0.04144375 -0.22156734 -0.08471036\n",
      " -0.17083156 -0.09554261 -0.22588465]\n",
      "A média dos scores é de: -0.11359607196300421\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "10 número de árvores,\n",
      "10 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.02237601 -0.2236068  -0.07130164 -0.13027308 -0.11401754 -0.06761863\n",
      " -0.00062619 -0.08065543 -0.17175564 -0.06992059 -0.2236068  -0.09350066\n",
      " -0.17897326 -0.12609161 -0.18353259]\n",
      "A média dos scores é de: -0.11719042963275701\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "10 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.00469345 -0.22808605 -0.03484061 -0.12254015 -0.13132901 -0.05340153\n",
      " -0.00046737 -0.08601887 -0.15081629 -0.05287245 -0.22405357 -0.07240359\n",
      " -0.19398953 -0.08314616 -0.21682839]\n",
      "A média dos scores é de: -0.11036580064478775\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "10 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.00075962 -0.23714185 -0.04376077 -0.1382833  -0.13731767 -0.04708755\n",
      " -0.00091388 -0.11019181 -0.14850436 -0.04144375 -0.22156734 -0.08471036\n",
      " -0.17083156 -0.09554261 -0.22588465]\n",
      "A média dos scores é de: -0.11359607196300421\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "10 número de árvores,\n",
      "15 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.02236068 -0.2236068  -0.07071068 -0.12247449 -0.11401754 -0.1\n",
      " -0.         -0.08062258 -0.17175564 -0.07745967 -0.2236068  -0.08944272\n",
      " -0.17464249 -0.13687991 -0.18353259]\n",
      "A média dos scores é de: -0.11940750539431194\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "15 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.00451754 -0.22807893 -0.03310757 -0.11061287 -0.13145579 -0.06679259\n",
      " -0.         -0.0779025  -0.15418684 -0.05796551 -0.22405357 -0.07155418\n",
      " -0.19297668 -0.08521779 -0.2170171 ]\n",
      "A média dos scores é de: -0.11036263003801369\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "15 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.0004687  -0.23713701 -0.04432668 -0.13466829 -0.13671811 -0.0558672\n",
      " -0.00071744 -0.10285516 -0.15124231 -0.04131903 -0.22158267 -0.08328607\n",
      " -0.17255532 -0.09512376 -0.22544442]\n",
      "A média dos scores é de: -0.11355414388600442\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "10 número de árvores,\n",
      "15 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.02236068 -0.2236068  -0.07071068 -0.12247449 -0.11401754 -0.1\n",
      " -0.         -0.08062258 -0.17175564 -0.07745967 -0.2236068  -0.08944272\n",
      " -0.17464249 -0.124499   -0.18353259]\n",
      "A média dos scores é de: -0.11858211079767013\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "15 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.00447214 -0.22807893 -0.03316625 -0.11054411 -0.1275931  -0.07\n",
      " -0.         -0.077846   -0.15767054 -0.05796551 -0.22405357 -0.07155418\n",
      " -0.19297668 -0.07924645 -0.2159922 ]\n",
      "A média dos scores é de: -0.1100773105008051\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "15 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.0003873  -0.23714184 -0.04377442 -0.13354269 -0.13722172 -0.05763636\n",
      " -0.00070711 -0.10108635 -0.15303921 -0.04155238 -0.22157425 -0.08321779\n",
      " -0.17190215 -0.0911869  -0.22492689]\n",
      "A média dos scores é de: -0.11325982295802424\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "10 número de árvores,\n",
      "15 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.02236068 -0.2236068  -0.07071068 -0.12247449 -0.11401754 -0.1\n",
      " -0.         -0.08062258 -0.17175564 -0.07745967 -0.2236068  -0.08944272\n",
      " -0.17464249 -0.124499   -0.18353259]\n",
      "A média dos scores é de: -0.11858211079767013\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "15 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.00447214 -0.22807893 -0.03316625 -0.11054411 -0.1275931  -0.07\n",
      " -0.         -0.077846   -0.15767054 -0.05796551 -0.22405357 -0.07155418\n",
      " -0.19297668 -0.07924645 -0.2159922 ]\n",
      "A média dos scores é de: -0.1100773105008051\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "15 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.0003873  -0.23714184 -0.04377442 -0.13354269 -0.13722172 -0.05763636\n",
      " -0.00070711 -0.10108635 -0.15303921 -0.04155238 -0.22157425 -0.08321779\n",
      " -0.17190215 -0.0911869  -0.22492689]\n",
      "A média dos scores é de: -0.11325982295802424\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "10 número de árvores,\n",
      "30 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.02236068 -0.2236068  -0.07071068 -0.12247449 -0.11401754 -0.1\n",
      " -0.         -0.08062258 -0.17175564 -0.07745967 -0.2236068  -0.08944272\n",
      " -0.17464249 -0.13687991 -0.18353259]\n",
      "A média dos scores é de: -0.11940750539431194\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "30 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.00451754 -0.22807893 -0.03310757 -0.11061287 -0.13145579 -0.06679259\n",
      " -0.         -0.0779025  -0.15418684 -0.05796551 -0.22405357 -0.07155418\n",
      " -0.19297668 -0.08521779 -0.2170171 ]\n",
      "A média dos scores é de: -0.11036263003801369\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "30 número de folhas e\n",
      "5 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.0004687  -0.23713701 -0.04432668 -0.13466829 -0.13671811 -0.0558672\n",
      " -0.00071744 -0.10285516 -0.15124231 -0.04131903 -0.22158267 -0.08328607\n",
      " -0.17255532 -0.09512376 -0.22544442]\n",
      "A média dos scores é de: -0.11355414388600442\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "10 número de árvores,\n",
      "30 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.02236068 -0.2236068  -0.07071068 -0.12247449 -0.11401754 -0.1\n",
      " -0.         -0.08062258 -0.17175564 -0.07745967 -0.2236068  -0.08944272\n",
      " -0.17464249 -0.124499   -0.18353259]\n",
      "A média dos scores é de: -0.11858211079767013\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "30 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.00447214 -0.22807893 -0.03316625 -0.11054411 -0.1275931  -0.07\n",
      " -0.         -0.077846   -0.15767054 -0.05796551 -0.22405357 -0.07155418\n",
      " -0.19297668 -0.07924645 -0.2159922 ]\n",
      "A média dos scores é de: -0.1100773105008051\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "30 número de folhas e\n",
      "10 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.0003873  -0.23714184 -0.04377442 -0.13354269 -0.13722172 -0.05763636\n",
      " -0.00070711 -0.10108635 -0.15303921 -0.04155238 -0.22157425 -0.08321779\n",
      " -0.17190215 -0.0911869  -0.22492689]\n",
      "A média dos scores é de: -0.11325982295802424\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "10 número de árvores,\n",
      "30 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.02236068 -0.2236068  -0.07071068 -0.12247449 -0.11401754 -0.1\n",
      " -0.         -0.08062258 -0.17175564 -0.07745967 -0.2236068  -0.08944272\n",
      " -0.17464249 -0.124499   -0.18353259]\n",
      "A média dos scores é de: -0.11858211079767013\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "50 número de árvores,\n",
      "30 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.00447214 -0.22807893 -0.03316625 -0.11054411 -0.1275931  -0.07\n",
      " -0.         -0.077846   -0.15767054 -0.05796551 -0.22405357 -0.07155418\n",
      " -0.19297668 -0.07924645 -0.2159922 ]\n",
      "A média dos scores é de: -0.1100773105008051\n",
      "\n",
      "Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \n",
      "1000 número de árvores,\n",
      "30 número de folhas e\n",
      "15 número de profundidade\n",
      "temos que:\n",
      "Os scores foram de: [-0.0003873  -0.23714184 -0.04377442 -0.13354269 -0.13722172 -0.05763636\n",
      " -0.00070711 -0.10108635 -0.15303921 -0.04155238 -0.22157425 -0.08321779\n",
      " -0.17190215 -0.0911869  -0.22492689]\n",
      "A média dos scores é de: -0.11325982295802424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----- Aqui o score estipulado é o RMSE\n",
    "NUM_ARVORES = [10, 50, 1000]\n",
    "NUM_FOLHAS = [10, 15, 30]\n",
    "NUM_PROFUNDIDADE = [5, 10, 15]\n",
    "NUM_FOLDS = 15\n",
    "NUM_CPU_CORES = 4\n",
    "\n",
    "for n_folhas, n_profundidade, n_arvores in product(\n",
    "    NUM_FOLHAS, NUM_PROFUNDIDADE, NUM_ARVORES\n",
    "):\n",
    "    modelo_rf = RandomForestRegressor(\n",
    "        n_estimators=n_arvores,\n",
    "        max_leaf_nodes=n_folhas,\n",
    "        max_depth=n_profundidade,\n",
    "        random_state=SEMENTE_ALEATORIA,\n",
    "        n_jobs= NUM_CPU_CORES,\n",
    "    )\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "    #modelo_rf.fit(x_treino, y_treino)\n",
    "    modelo_rf,\n",
    "    x_treino,\n",
    "    y_treino.ravel(), ## <----------------------------- Sem o .ravel um erro aparece.\n",
    "    cv=NUM_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Aplicando a métrica de erro RMSE para os seguintes hiperparâmetros: \\n\"\n",
    "        f\"{n_arvores} número de árvores,\\n\"\n",
    "        f\"{n_folhas} número de folhas e\\n\"\n",
    "        f\"{n_profundidade} número de profundidade\\n\"\n",
    "        f\"temos que:\\n\"\n",
    "        f\"Os scores foram de: {scores}\\n\"\n",
    "        f\"A média dos scores é de: {scores.mean()}\"\n",
    "        f\"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7fbc43-f219-47f0-bda9-0c684da9b616",
   "metadata": {},
   "source": [
    "# Afinal, apresentou Overfit ou não? \n",
    "\n",
    "Nos 27 modelos testados com k-fold, percebemos que não houve de fato overfit, já que os diferentes modelos manteram o resultado médio dentro de uma margem de erro muito próxima. Em R², o score de todos os testes deu um resultado muito bom de aproximadamente 0.97. Em RMSE, também teve um valor muito bom de aprozimadamente 0.11. Inclusive, o melhor modelo teve um dado bizarro, pois uma das predições foi perfeita. Mas, ainda assim, aparenta ter sido um caso de coincidencia e não de overfitting, já que a média dos scores continuou dentro do padrão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e3a705-9950-4e35-8364-e9b5557de2ee",
   "metadata": {},
   "source": [
    "Ademais, por causa desse resultado muito bom, acreditamos que o modelo de árvore de decisões é de fato um ótimo modelo de predições taxonômicas e diferenciação de espécie com base em dados de características físicas, que foi o nosso trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e76f78-8b49-40be-96ce-4725632ad617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
